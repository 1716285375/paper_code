# PPO自博弈训练配置 - MAgent2 battle_v4环境（快速测试版本）
# 用于快速验证代码和配置是否正确的简化配置
# 训练步数、批次大小等都已减小，便于快速测试

# 环境配置
env:
  name: "magent2:battle_v4"
  map_size: 45
  minimap_mode: false
  max_cycles: 500
  step_reward: -0.005
  dead_penalty: -0.1
  attack_penalty: -0.1
  attack_opponent_reward: 0.2

# Agent配置
agent:
  type: "ppo"
  obs_dim: 845  # battle_v4的观测维度（如果minimap_mode=false）
  action_dim: 21  # battle_v4的动作空间维度
  
  encoder:
    type: "networks/mlp"
    params:
      in_dim: 845
      hidden_dims: [256, 128]  # 减小网络规模以加快训练
      use_layer_norm: true
      dropout: 0.0
  
  policy_head:
    type: "policy_heads/discrete"
    params:
      hidden_dims: [64]
  
  value_head:
    type: "value_heads/mlp"
    params:
      hidden_dims: [64]
  
  optimizer:
    type: "optimizers/adam"
    params:
      lr: 3e-4
      scheduler: "linear"
      warmup_steps: 100  # 减小warmup步数
      total_steps: 1000  # 减小总步数
      weight_decay: 0.0
      max_grad_norm: 0.5

# 训练配置（快速测试版本）
training:
  num_updates: 50  # 大幅减少：从10000减少到50，用于快速测试
  max_steps_per_episode: 100  # 减小：从500减少到100，加快episode速度
  num_epochs: 2  # 减少：从4减少到2，加快训练速度
  batch_size: 512  # 减小：从2048减少到512，减少内存占用和训练时间
  clip_coef: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  gamma: 0.99
  gae_lambda: 0.95
  
  # 自博弈配置
  self_play_update_freq: 5  # 减小：从10减少到5，更频繁地更新对手策略以便观察效果
  self_play_mode: "copy"  # "copy" 或 "pool"
  use_policy_pool: false  # 测试时禁用策略池
  policy_pool_size: 10  # 策略池大小（如果启用）
  
  # 主团队和对手团队（在Magent2中通常是"team_red"和"team_blue"）
  main_team: "team_red"
  opponent_team: "team_blue"
  
  # 评估和保存（更频繁以便观察测试进度）
  eval_freq: 10  # 减小：从50减少到10，更频繁评估
  save_freq: 20  # 减小：从100减少到20，更频繁保存
  log_freq: 1  # 减小：从10减少到1，每次更新都记录日志

# 设备配置
device: "cuda"  # "cuda" 或 "cpu"

# 随机种子
seed: 42

# 实验跟踪配置（wandb/tensorboard）
# 测试时可以禁用或使用离线模式
tracking:
  enabled: true  # 保持启用，但可以设置为false以加快测试
  
  # WandB配置（可选）
  wandb:
    enabled: false  # 测试时建议禁用，或设置为离线模式（需要修改代码）
    project: "magent2-selfplay-test"  # WandB项目名称
    name: null  # 运行名称（如果为null则自动生成）
  
  # TensorBoard配置（可选）
  tensorboard:
    enabled: true  # 保持启用，便于本地查看
    experiment_name: "magent2-selfplay-test"  # 实验名称

# 训练数据保存配置（用于本地分析和绘图）
data_saving:
  enabled: true  # 是否启用数据保存
  output_dir: "training_data"  # 数据保存目录（相对于项目根目录）
  format: "both"  # 保存格式："json", "csv", "both"
  
  # 视频录制配置
  record_video:
    enabled: false  # 是否录制评估episode的视频（会增加训练时间）
    fps: 30  # 视频帧率
    # 注意：需要环境支持render(mode="rgb_array")

